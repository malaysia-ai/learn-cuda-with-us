{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab7516a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "221b10aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1000, 2000, 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b50fb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_626257/2174467088.py:1: RuntimeWarning: overflow encountered in exp\n",
      "  numerator = np.exp(x)\n",
      "/tmp/ipykernel_626257/2174467088.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  softmax = numerator / denominator\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerator = np.exp(x)\n",
    "denominator = np.sum(numerator)\n",
    "\n",
    "softmax = numerator / denominator\n",
    "softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb25764",
   "metadata": {},
   "source": [
    "## we got overflow! So we need to do safe softmax.\n",
    "\n",
    "### 1. minus max trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93dc2a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_max = np.max(x)\n",
    "numerator = np.exp(x - x_max)\n",
    "denominator = np.sum(numerator)\n",
    "softmax = numerator / denominator\n",
    "softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40426f97",
   "metadata": {},
   "source": [
    "The reason why this is working because exponent negative is closer to 0 but exponent positive is infinitely increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f7d1317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_626257/2006519253.py:1: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f69af578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df82a72",
   "metadata": {},
   "source": [
    "### 2. LSE trick\n",
    "\n",
    "Log (A/B) = Log (A) âˆ’ Log (B)\n",
    "\n",
    "LSE = Log Sum Exponent, which is the denominator, or Log (B).\n",
    "\n",
    "While Log (A) = Log (exp^A) = A.\n",
    "\n",
    "but this one you got log softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0889cc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2000., -1000.,     0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax = x - (x_max + np.log(np.sum(np.exp(x - x_max))))\n",
    "log_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a15af27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(log_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c530a9",
   "metadata": {},
   "source": [
    "## Online softmax\n",
    "\n",
    "If you have huge matrix, calculating softmax is very expensive, actually we can do it by chunk by calculating the global values.\n",
    "\n",
    "The paper from https://arxiv.org/pdf/1805.02867"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40f81b30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7492090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000, 2000, 3000]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dff7487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, d = -np.inf, 0\n",
    "for x_ in x:\n",
    "    m_ = max(m, x_)\n",
    "    d = d * np.exp(m - m_) + np.exp(x_ - m_)\n",
    "    m = m_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20097640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(np.array(x) - m) / d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8d75ae",
   "metadata": {},
   "source": [
    "### Go bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0701083",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(size = (10000))\n",
    "splitted = np.split(x, 10)\n",
    "chunks = []\n",
    "for s in splitted:\n",
    "    m, d = -np.inf, 0\n",
    "    for x_ in s:\n",
    "        m_ = max(m, x_)\n",
    "        d = d * np.exp(m - m_) + np.exp(x_ - m_)\n",
    "        m = m_\n",
    "    chunks.append((m, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7323e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_global = -np.inf\n",
    "for m, _ in chunks:\n",
    "    m_global = max(m_global, m)\n",
    "\n",
    "d_global = 0\n",
    "for m, d in chunks:\n",
    "    d_global += d * np.exp(m - m_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "175a5a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999996"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.exp(x - m_global) / d_global)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
